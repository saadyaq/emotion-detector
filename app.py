import streamlit as st
import sounddevice as sd
from scipy.io.wavfile import write
import numpy as np
import os
from joblib import load
from src.feature_extraction import extract_features  # ta fonction MFCC/chroma etc.

st.title("ğŸ™ï¸ DÃ©tecteur d'Ã‰motions Vocales")

duration = st.slider("DurÃ©e d'enregistrement (secondes)", 1, 10, 3)
fs = 22050  # frÃ©quence d'Ã©chantillonnage standard

if st.button("ğŸ¤ Enregistrer"):
    st.info("Enregistrement en cours...")
    devices = sd.query_devices()
    st.write(devices)
    sd.default.device = 1  # ou l'index du pÃ©riphÃ©rique avec un micro actif

    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)
    sd.wait()
    filepath = "audio_input.wav"
    write(filepath, fs, recording)
    st.success("Enregistrement terminÃ© !")

    # Extraire les features
    features = extract_features(filepath)
    if features:
        X_input = np.array(features.values()).reshape(1, -1)

        # Charger le modÃ¨le
        model = load("models/rf.joblib")
        prediction = model.predict(X_input)[0]

        st.subheader("ğŸ§  Ã‰motion dÃ©tectÃ©e :")
        st.success(prediction)
    else:
        st.error("Impossible d'extraire les features.")
